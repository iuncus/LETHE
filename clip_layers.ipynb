{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "# import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from collections import OrderedDict\n",
    "\n",
    "# from data import AblatingDataset\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "text_model\n",
      "text_model.embeddings\n",
      "text_model.embeddings.token_embedding\n",
      "text_model.embeddings.position_embedding\n",
      "text_model.encoder\n",
      "text_model.encoder.layers\n",
      "text_model.encoder.layers.0\n",
      "text_model.encoder.layers.0.self_attn\n",
      "text_model.encoder.layers.0.self_attn.k_proj\n",
      "text_model.encoder.layers.0.self_attn.v_proj\n",
      "text_model.encoder.layers.0.self_attn.q_proj\n",
      "text_model.encoder.layers.0.self_attn.out_proj\n",
      "text_model.encoder.layers.0.layer_norm1\n",
      "text_model.encoder.layers.0.mlp\n",
      "text_model.encoder.layers.0.mlp.activation_fn\n",
      "text_model.encoder.layers.0.mlp.fc1\n",
      "text_model.encoder.layers.0.mlp.fc2\n",
      "text_model.encoder.layers.0.layer_norm2\n",
      "text_model.encoder.layers.1\n",
      "text_model.encoder.layers.1.self_attn\n",
      "text_model.encoder.layers.1.self_attn.k_proj\n",
      "text_model.encoder.layers.1.self_attn.v_proj\n",
      "text_model.encoder.layers.1.self_attn.q_proj\n",
      "text_model.encoder.layers.1.self_attn.out_proj\n",
      "text_model.encoder.layers.1.layer_norm1\n",
      "text_model.encoder.layers.1.mlp\n",
      "text_model.encoder.layers.1.mlp.activation_fn\n",
      "text_model.encoder.layers.1.mlp.fc1\n",
      "text_model.encoder.layers.1.mlp.fc2\n",
      "text_model.encoder.layers.1.layer_norm2\n",
      "text_model.encoder.layers.2\n",
      "text_model.encoder.layers.2.self_attn\n",
      "text_model.encoder.layers.2.self_attn.k_proj\n",
      "text_model.encoder.layers.2.self_attn.v_proj\n",
      "text_model.encoder.layers.2.self_attn.q_proj\n",
      "text_model.encoder.layers.2.self_attn.out_proj\n",
      "text_model.encoder.layers.2.layer_norm1\n",
      "text_model.encoder.layers.2.mlp\n",
      "text_model.encoder.layers.2.mlp.activation_fn\n",
      "text_model.encoder.layers.2.mlp.fc1\n",
      "text_model.encoder.layers.2.mlp.fc2\n",
      "text_model.encoder.layers.2.layer_norm2\n",
      "text_model.encoder.layers.3\n",
      "text_model.encoder.layers.3.self_attn\n",
      "text_model.encoder.layers.3.self_attn.k_proj\n",
      "text_model.encoder.layers.3.self_attn.v_proj\n",
      "text_model.encoder.layers.3.self_attn.q_proj\n",
      "text_model.encoder.layers.3.self_attn.out_proj\n",
      "text_model.encoder.layers.3.layer_norm1\n",
      "text_model.encoder.layers.3.mlp\n",
      "text_model.encoder.layers.3.mlp.activation_fn\n",
      "text_model.encoder.layers.3.mlp.fc1\n",
      "text_model.encoder.layers.3.mlp.fc2\n",
      "text_model.encoder.layers.3.layer_norm2\n",
      "text_model.encoder.layers.4\n",
      "text_model.encoder.layers.4.self_attn\n",
      "text_model.encoder.layers.4.self_attn.k_proj\n",
      "text_model.encoder.layers.4.self_attn.v_proj\n",
      "text_model.encoder.layers.4.self_attn.q_proj\n",
      "text_model.encoder.layers.4.self_attn.out_proj\n",
      "text_model.encoder.layers.4.layer_norm1\n",
      "text_model.encoder.layers.4.mlp\n",
      "text_model.encoder.layers.4.mlp.activation_fn\n",
      "text_model.encoder.layers.4.mlp.fc1\n",
      "text_model.encoder.layers.4.mlp.fc2\n",
      "text_model.encoder.layers.4.layer_norm2\n",
      "text_model.encoder.layers.5\n",
      "text_model.encoder.layers.5.self_attn\n",
      "text_model.encoder.layers.5.self_attn.k_proj\n",
      "text_model.encoder.layers.5.self_attn.v_proj\n",
      "text_model.encoder.layers.5.self_attn.q_proj\n",
      "text_model.encoder.layers.5.self_attn.out_proj\n",
      "text_model.encoder.layers.5.layer_norm1\n",
      "text_model.encoder.layers.5.mlp\n",
      "text_model.encoder.layers.5.mlp.activation_fn\n",
      "text_model.encoder.layers.5.mlp.fc1\n",
      "text_model.encoder.layers.5.mlp.fc2\n",
      "text_model.encoder.layers.5.layer_norm2\n",
      "text_model.encoder.layers.6\n",
      "text_model.encoder.layers.6.self_attn\n",
      "text_model.encoder.layers.6.self_attn.k_proj\n",
      "text_model.encoder.layers.6.self_attn.v_proj\n",
      "text_model.encoder.layers.6.self_attn.q_proj\n",
      "text_model.encoder.layers.6.self_attn.out_proj\n",
      "text_model.encoder.layers.6.layer_norm1\n",
      "text_model.encoder.layers.6.mlp\n",
      "text_model.encoder.layers.6.mlp.activation_fn\n",
      "text_model.encoder.layers.6.mlp.fc1\n",
      "text_model.encoder.layers.6.mlp.fc2\n",
      "text_model.encoder.layers.6.layer_norm2\n",
      "text_model.encoder.layers.7\n",
      "text_model.encoder.layers.7.self_attn\n",
      "text_model.encoder.layers.7.self_attn.k_proj\n",
      "text_model.encoder.layers.7.self_attn.v_proj\n",
      "text_model.encoder.layers.7.self_attn.q_proj\n",
      "text_model.encoder.layers.7.self_attn.out_proj\n",
      "text_model.encoder.layers.7.layer_norm1\n",
      "text_model.encoder.layers.7.mlp\n",
      "text_model.encoder.layers.7.mlp.activation_fn\n",
      "text_model.encoder.layers.7.mlp.fc1\n",
      "text_model.encoder.layers.7.mlp.fc2\n",
      "text_model.encoder.layers.7.layer_norm2\n",
      "text_model.encoder.layers.8\n",
      "text_model.encoder.layers.8.self_attn\n",
      "text_model.encoder.layers.8.self_attn.k_proj\n",
      "text_model.encoder.layers.8.self_attn.v_proj\n",
      "text_model.encoder.layers.8.self_attn.q_proj\n",
      "text_model.encoder.layers.8.self_attn.out_proj\n",
      "text_model.encoder.layers.8.layer_norm1\n",
      "text_model.encoder.layers.8.mlp\n",
      "text_model.encoder.layers.8.mlp.activation_fn\n",
      "text_model.encoder.layers.8.mlp.fc1\n",
      "text_model.encoder.layers.8.mlp.fc2\n",
      "text_model.encoder.layers.8.layer_norm2\n",
      "text_model.encoder.layers.9\n",
      "text_model.encoder.layers.9.self_attn\n",
      "text_model.encoder.layers.9.self_attn.k_proj\n",
      "text_model.encoder.layers.9.self_attn.v_proj\n",
      "text_model.encoder.layers.9.self_attn.q_proj\n",
      "text_model.encoder.layers.9.self_attn.out_proj\n",
      "text_model.encoder.layers.9.layer_norm1\n",
      "text_model.encoder.layers.9.mlp\n",
      "text_model.encoder.layers.9.mlp.activation_fn\n",
      "text_model.encoder.layers.9.mlp.fc1\n",
      "text_model.encoder.layers.9.mlp.fc2\n",
      "text_model.encoder.layers.9.layer_norm2\n",
      "text_model.encoder.layers.10\n",
      "text_model.encoder.layers.10.self_attn\n",
      "text_model.encoder.layers.10.self_attn.k_proj\n",
      "text_model.encoder.layers.10.self_attn.v_proj\n",
      "text_model.encoder.layers.10.self_attn.q_proj\n",
      "text_model.encoder.layers.10.self_attn.out_proj\n",
      "text_model.encoder.layers.10.layer_norm1\n",
      "text_model.encoder.layers.10.mlp\n",
      "text_model.encoder.layers.10.mlp.activation_fn\n",
      "text_model.encoder.layers.10.mlp.fc1\n",
      "text_model.encoder.layers.10.mlp.fc2\n",
      "text_model.encoder.layers.10.layer_norm2\n",
      "text_model.encoder.layers.11\n",
      "text_model.encoder.layers.11.self_attn\n",
      "text_model.encoder.layers.11.self_attn.k_proj\n",
      "text_model.encoder.layers.11.self_attn.v_proj\n",
      "text_model.encoder.layers.11.self_attn.q_proj\n",
      "text_model.encoder.layers.11.self_attn.out_proj\n",
      "text_model.encoder.layers.11.layer_norm1\n",
      "text_model.encoder.layers.11.mlp\n",
      "text_model.encoder.layers.11.mlp.activation_fn\n",
      "text_model.encoder.layers.11.mlp.fc1\n",
      "text_model.encoder.layers.11.mlp.fc2\n",
      "text_model.encoder.layers.11.layer_norm2\n",
      "text_model.final_layer_norm\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPTextModel\n",
    "\n",
    "# pipe = StableDiffusionPipeline.from_pretrained(model, safety_checker=None).to(device)\n",
    "# pipe.tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\", low_cpu_mem_usage=False)\n",
    "# text_encoder = CLIPTextModel.from_pretrained(\"updated_CLIP/R_maximize_BG_first_attn_all_100_2/epoch-26\", low_cpu_mem_usage=False)\n",
    "\n",
    "# pipe.scheduler =  PNDMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000, skip_prk_steps=True, steps_offset=1)\n",
    "# pipe.scheduler.config.prediction_type\n",
    "# # pipe.tokenizer.to(device)\n",
    "# pipe.text_encoder.to(device)\n",
    "# pipe.unet.to(device)\n",
    "# pipe.scheduler.to(device)\n",
    "\n",
    "\n",
    "# tokenizer, text_encoder, vae, unet, scheduler = utils.load_models_from_local_optioned_path(\n",
    "#     text_encoder_path=\"openai/clip-vit-large-patch14\",\n",
    "#     unet_path=\"models/sd-15/unet\",\n",
    "#     vae_path=\"models/sd-15/vae\",\n",
    "#     tokenizer_version=\"openai/clip-vit-large-patch14\",\n",
    "# )\n",
    "\n",
    "# unet.to(device)\n",
    "# text_encoder.to(device)\n",
    "# # vae.to(device)\n",
    "# pipe.vae.eval()\n",
    "\n",
    "# # freeze unet parameters\n",
    "# for param in pipe.unet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "\n",
    "# # text_encoder = utils.freeze_and_unfreeze_text_encoder(pipe.text_encoder, method=\"mlp-final-attn\")\n",
    "# text_encoder = pipe.text_encoder\n",
    "# for param in text_encoder.parameters():\n",
    "#     param.require_grad = False\n",
    "\n",
    "for param_name, module in text_encoder.named_modules():\n",
    "    print(param_name)\n",
    "    # if \"0.self_attn.\" in param_name:\n",
    "    # # if \"mlp.fc\" in param_name:\n",
    "    #     for param in module.parameters():\n",
    "    #         param.requires_grad = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kohya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
